{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveengovianalytics/Building-Trustworthy-LLM-Apps-and-Evaluating-LLM-agents-/blob/main/Evaluate_RAG_with_Trulens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA9Yzycwojt_"
      },
      "source": [
        "# 📓 Evaluate RAG with Trulens\n",
        "\n",
        "In this quickstart you will create a RAG from scratch and learn how to log it and get feedback on an LLM response.\n",
        "\n",
        "For evaluation, we will leverage the \"hallucination triad\" of groundedness, context relevance and answer relevance.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/quickstart.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwEH9UKuojuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b0b321-c647-447b-ecc2-a608bbc84d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.1/657.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.4/502.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.1/816.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.8/680.8 kB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for millify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install trulens_eval==0.23.0 chromadb==0.4.18 openai==1.3.7 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSgfjpzQojuG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Aley7oKtDQ3B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3Z719qTojuH"
      },
      "source": [
        "## Get Data\n",
        "\n",
        "In this case, we'll just initialize some simple text in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq2OJErXojuI"
      },
      "outputs": [],
      "source": [
        "llm_details = \"\"\"\n",
        "Large language model definition\n",
        "A large language model (LLM) is a deep learning algorithm that can perform a variety of natural language processing (NLP) tasks. Large language models use transformer models and are trained using massive datasets — hence, large. This enables them to recognize, translate, predict, or generate text or other content.\n",
        "\n",
        "Large language models are also referred to as neural networks (NNs), which are computing systems inspired by the human brain. These neural networks work using a network of nodes that are layered, much like neurons.\n",
        "\n",
        "In addition to teaching human languages to artificial intelligence (AI) applications, large language models can also be trained to perform a variety of tasks like understanding protein structures, writing software code, and more. Like the human brain, large language models must be pre-trained and then fine-tuned so that they can solve text classification, question answering, document summarization, and text generation problems. Their problem-solving capabilities can be applied to fields like healthcare, finance, and entertainment where large language models serve a variety of NLP applications, such as translation, chatbots, AI assistants, and so on.\n",
        "\n",
        "Large language models also have large numbers of parameters, which are akin to memories the model collects as it learns from training. Think of these parameters as the model’s knowledge bank.\n",
        "\n",
        "So, what is a transformer model?\n",
        "A transformer model is the most common architecture of a large language model. It consists of an encoder and a decoder. A transformer model processes data by tokenizing the input, then simultaneously conducting mathematical equations to discover relationships between tokens. This enables the computer to see the patterns a human would see were it given the same query.\n",
        "\n",
        "Transformer models work with self-attention mechanisms, which enables the model to learn more quickly than traditional models like long short-term memory models. Self-attention is what enables the transformer model to consider different parts of the sequence, or the entire context of a sentence, to generate predictions.\n",
        "\n",
        "Related: Apply transformers to your search applications\n",
        "\n",
        "Key components of large language models\n",
        "Large language models are composed of multiple neural network layers. Recurrent layers, feedforward layers, embedding layers, and attention layers work in tandem to process the input text and generate output content.\n",
        "\n",
        "The embedding layer creates embeddings from the input text. This part of the large language model captures the semantic and syntactic meaning of the input, so the model can understand context.\n",
        "\n",
        "The feedforward layer (FFN) of a large language model is made of up multiple fully connected layers that transform the input embeddings. In so doing, these layers enable the model to glean higher-level abstractions — that is, to understand the user's intent with the text input.\n",
        "\n",
        "The recurrent layer interprets the words in the input text in sequence. It captures the relationship between words in a sentence.\n",
        "\n",
        "The attention mechanism enables a language model to focus on single parts of the input text that is relevant to the task at hand. This layer allows the model to generate the most accurate outputs.\n",
        "\n",
        "There are three main kinds of large language models:\n",
        "\n",
        "Generic or raw language models predict the next word based on the language in the training data. These language models perform information retrieval tasks.\n",
        "Instruction-tuned language models are trained to predict responses to the instructions given in the input. This allows them to perform sentiment analysis, or to generate text or code.\n",
        "Dialog-tuned language models are trained to have a dialog by predicting the next response. Think of chatbots or conversational AI.\n",
        "What is the difference between large language models and generative AI?\n",
        "Generative AI is an umbrella term that refers to artificial intelligence models that have the capability to generate content. Generative AI can generate text, code, images, video, and music. Examples of generative AI include Midjourney, DALL-E, and ChatGPT.\n",
        "\n",
        "Large language models are a type of generative AI that are trained on text and produce textual content. ChatGPT is a popular example of generative text AI.\n",
        "\n",
        "All large language models are generative AI1.\n",
        "\n",
        "How do large language models work?\n",
        "A large language model is based on a transformer model and works by receiving an input, encoding it, and then decoding it to produce an output prediction. But before a large language model can receive text input and generate an output prediction, it requires training, so that it can fulfill general functions, and fine-tuning, which enables it to perform specific tasks.\n",
        "\n",
        "Training: Large language models are pre-trained using large textual datasets from sites like Wikipedia, GitHub, or others. These datasets consist of trillions of words, and their quality will affect the language model's performance. At this stage, the large language model engages in unsupervised learning, meaning it processes the datasets fed to it without specific instructions. During this process, the LLM's AI algorithm can learn the meaning of words, and of the relationships between words. It also learns to distinguish words based on context. For example, it would learn to understand whether \"right\" means \"correct,\" or the opposite of \"left.\"\n",
        "\n",
        "Fine-tuning: In order for a large language model to perform a specific task, such as translation, it must be fine-tuned to that particular activity. Fine-tuning optimizes the performance of specific tasks.\n",
        "\n",
        "Prompt-tuning fulfills a similar function to fine-tuning, whereby it trains a model to perform a specific task through few-shot prompting, or zero-shot prompting. A prompt is an instruction given to an LLM. Few-shot prompting teaches the model to predict outputs through the use of examples. For instance, in this sentiment analysis exercise, a few-shot prompt would look like this:\n",
        "\n",
        "Customer review: This plant is so beautiful!\n",
        "Customer sentiment: positive\n",
        "\n",
        "Customer review: This plant is so hideous!\n",
        "Customer sentiment: negative\n",
        "The language model would understand, through the semantic meaning of \"hideous,\" and because an opposite example was provided, that the customer sentiment in the second example is \"negative.\"\n",
        "\n",
        "Alternatively, zero-shot prompting does not use examples to teach the language model how to respond to inputs. Instead, it formulates the question as \"The sentiment in ‘This plant is so hideous' is….\" It clearly indicates which task the language model should perform, but does not provide problem-solving examples.\n",
        "\n",
        "Large language models use cases\n",
        "Large language models can be used for several purposes:\n",
        "\n",
        "Information retrieval: Think of Bing or Google. Whenever you use their search feature, you are relying on a large language model to produce information in response to a query. It's able to retrieve information, then summarize and communicate the answer in a conversational style.\n",
        "Sentiment analysis: As applications of natural language processing, large language models enable companies to analyze the sentiment of textual data.\n",
        "Text generation: Large language models are behind generative AI, like ChatGPT, and can generate text based on inputs. They can produce an example of text when prompted. For example: \"Write me a poem about palm trees in the style of Emily Dickinson.\"\n",
        "Code generation: Like text generation, code generation is an application of generative AI. LLMs understand patterns, which enables them to generate code.\n",
        "Chatbots and conversational AI: Large language models enable customer service chatbots or conversational AI to engage with customers, interpret the meaning of their queries or responses, and offer responses in turn.\n",
        "In addition to these use cases, large language models can complete sentences, answer questions, and summarize text.\n",
        "\n",
        "With such a wide variety of applications, large language applications can be found in a multitude of fields:\n",
        "\n",
        "Tech: Large language models are used anywhere from enabling search engines to respond to queries, to assisting developers with writing code.\n",
        "Healthcare and Science: Large language models have the ability to understand proteins, molecules, DNA, and RNA. This position allows LLMs to assist in the development of vaccines, finding cures for illnesses, and improving preventative care medicines. LLMs are also used as medical chatbots to perform patient intakes or basic diagnoses.\n",
        "Customer Service: LLMs are used across industries for customer service purposes such as chatbots or conversational AI.\n",
        "Marketing: Marketing teams can use LLMs to perform sentiment analysis to quickly generate campaign ideas or text as pitching examples, and much more.\n",
        "Legal: From searching through massive textual datasets to generating legalese, large language models can assist lawyers, paralegals, and legal staff.\n",
        "Banking: LLMs can support credit card companies in detecting fraud.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jucy_yhiojuI"
      },
      "source": [
        "## Create Vector Store\n",
        "\n",
        "Create a chromadb vector store in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAvd5IosojuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4e08d4-621e-41fb-a583-0861141cb2cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CreateEmbeddingResponse(data=[Embedding(embedding=[-0.025398574769496918, 0.021891215816140175, -0.003533829702064395, -0.010336782783269882, 0.00013731641229242086, -0.00588309857994318, -0.0031102995853871107, 0.019733859226107597, -0.019826505333185196, -0.0589236319065094, 0.013751494698226452, 0.03330006077885628, -0.022407392039895058, 0.010760312899947166, -0.0027347474824637175, 0.006481996737420559, 0.020872095599770546, 0.011428697034716606, 0.009582369588315487, -0.02010444737970829, -0.0026007399428635836, -0.015458851121366024, -0.01845003291964531, -0.028667697682976723, -0.015220615081489086, 0.006601114757359028, 0.02664269506931305, -0.04674714058637619, -0.00989339966326952, 0.006534938234835863, 0.013791200704872608, 0.01801326684653759, -0.022592686116695404, 0.004179051611572504, 0.009886782616376877, 0.007736043073236942, 0.030255936086177826, -0.005211406387388706, 0.019098563119769096, -0.02144121378660202, 0.023982394486665726, 0.0399177186191082, 0.00976104661822319, -0.027529461309313774, -0.003044123062863946, 0.011296343058347702, 0.00046613134327344596, -0.02652357704937458, -4.7228368202922866e-05, 0.007259571459144354, 0.03067946620285511, 0.04312066361308098, -0.032029468566179276, 0.0011357556795701385, -0.03607947379350662, 0.00469192024320364, -0.0020845625549554825, 0.006908835843205452, 0.027926519513130188, -0.02640445902943611, -0.004228684119880199, 0.002681806217879057, -0.013096346519887447, 0.018052972853183746, 0.004979788325726986, -0.013923553749918938, -0.012586787343025208, 0.027502989396452904, 0.004592655226588249, -0.008258838206529617, 0.021361801773309708, 0.010482371784746647, 0.0041426545940339565, -0.002312871627509594, 0.015591204166412354, 0.009972811676561832, 0.003950742073357105, -0.01138899102807045, -0.024776514619588852, 0.00588971609249711, 0.012355169281363487, -0.01684855856001377, 0.0006514257984235883, 0.019151505082845688, 0.015154439024627209, -0.0026090119499713182, 0.003272432368248701, -0.03295594081282616, -0.009158839471638203, -0.00015778980741742998, -0.002501474926248193, -0.010350018739700317, 0.012871346436440945, 0.0007238064426928759, 0.026457399129867554, -0.013096346519887447, -0.0030772113241255283, -0.010905901901423931, 0.005704422015696764, -0.02134856767952442, -0.012414728291332722, 0.0021126875653862953, -0.044814784079790115, -0.012163257226347923, -0.02426033653318882, 0.018119148910045624, 0.011150754988193512, 0.006343025714159012, 0.018900033086538315, 0.002380702644586563, -0.011064724996685982, 0.023452982306480408, 0.004668758250772953, -0.043941255658864975, 0.013658847659826279, -0.004900376312434673, 0.013751494698226452, -0.015577969141304493, 0.01969415321946144, -0.005532362498342991, 0.032347116619348526, 0.015842674300074577, 0.013281641528010368, -0.014823555946350098, 0.0255971048027277, -0.008530162274837494, 0.007239718921482563, -0.019270623102784157, -0.037191241979599, 0.0014509216416627169, -0.015141203068196774, 0.004179051611572504, 0.0019174666376784444, 0.01070737186819315, -0.02795299142599106, 0.024776514619588852, 0.005750745534896851, -0.004794493783265352, -0.021600037813186646, -0.0009992665145546198, 0.016425028443336487, 0.02797946147620678, -0.015511792153120041, 0.00797427911311388, -0.01092575490474701, 0.017536796629428864, 0.00253125443123281, 0.01575002819299698, 0.010177958756685257, -0.004261772148311138, 0.008953692391514778, -0.02202356792986393, -0.0027794167399406433, 0.0076367780566215515, 0.018225032836198807, 0.026457399129867554, 0.01339414156973362, 0.025663280859589577, -0.033458881080150604, -0.013387523591518402, -0.007471336517482996, 0.017192676663398743, -0.007927955128252506, 0.019138269126415253, 0.010244135744869709, 0.024538278579711914, 0.007616925053298473, -0.008854427374899387, -0.0110713429749012, -0.007305895444005728, -0.006988247856497765, 0.04224713519215584, -0.03994418680667877, 0.02231474593281746, -0.006521702744066715, -0.0019720622804015875, 0.04044713079929352, -0.0220500398427248, -0.009827223606407642, -0.01711326465010643, 0.037985362112522125, 0.011011783964931965, 0.007391924969851971, 0.002541180932894349, -0.0336441770195961, -0.030573584139347076, 0.008497074246406555, -0.010548547841608524, 0.016689734533429146, -0.023836806416511536, 0.0039904480800032616, 0.03033534809947014, 0.012911052443087101, -0.03099711425602436, -0.616659939289093, -0.023863278329372406, 0.01062134187668562, -0.002681806217879057, 0.004635669756680727, -0.0010480716591700912, -0.016782382503151894, -0.0075639840215444565, -0.007815455086529255, 0.0221426859498024, -0.01949562318623066, -0.021785331889986992, -0.015723558142781258, -0.00019553113088477403, -0.0015303335385397077, -0.007511042524129152, -0.008000749163329601, -0.02170591987669468, 0.013751494698226452, 0.007590454537421465, -0.018807386979460716, 0.014519142918288708, -0.02693387120962143, 0.004701846744865179, -0.03094417229294777, 0.016451500356197357, 0.005486038979142904, 0.00784192606806755, 0.0294618159532547, 0.009946340695023537, -0.030917702242732048, -0.006981629878282547, 0.01056178379803896, 0.0029068065341562033, 0.042988311499357224, 0.022010333836078644, -0.014691202901303768, 0.023982394486665726, 0.01117060799151659, 0.01813238486647606, -0.0032112188637256622, -0.02594122290611267, -0.012891199439764023, 0.005231259390711784, -0.00017123192083090544, 0.027502989396452904, 0.01604120433330536, 0.011885315179824829, -0.008285309188067913, -0.0145720848813653, -0.00880148634314537, 0.015577969141304493, 0.00716030690819025, -0.007398542482405901, 0.00871545635163784, -0.0013930171262472868, 0.033485352993011475, -0.006789717823266983, 0.01978679932653904, -0.01140222605317831, 0.014545613899827003, -0.010244135744869709, -0.0223676860332489, -0.002092834562063217, -0.006174275651574135, 0.010641194880008698, 0.017060324549674988, 0.0016775764524936676, -0.02414121851325035, -0.024498572573065758, 0.00028125051176175475, 0.023320630192756653, 0.01606767624616623, -0.012090462259948254, -0.009727958589792252, 0.01490296795964241, 0.008199279196560383, -0.00458934623748064, -0.002736401977017522, 0.009423546493053436, 0.032638292759656906, -0.015101497061550617, -0.004129419103264809, -0.02629857510328293, 0.021798567846417427, 0.013592670671641827, 0.020382389426231384, 0.007980896160006523, -0.0006716923671774566, 0.017205912619829178, 0.008900751359760761, 0.02710593119263649, -0.02054121345281601, -0.0727413073182106, -0.027158871293067932, 0.01271252240985632, -0.016014734283089638, 0.004880523309111595, 0.01687503047287464, -0.0027000047266483307, 0.014201495796442032, -0.010237517766654491, 0.02199709787964821, 0.02678828313946724, 0.013910318724811077, 0.003742286004126072, 0.0007051942520774901, 0.02437945455312729, 0.01725885458290577, -0.02922358177602291, -0.004708464257419109, 0.0003482542815618217, -0.003742286004126072, -0.0017917311051860452, 0.005108832381665707, -0.02124268375337124, -0.0044404491782188416, -0.009423546493053436, 0.0028207770083099604, -0.02579563297331333, 0.017642678692936897, 0.00542647996917367, 0.01806620880961418, -0.0014062525006011128, 0.01459855493158102, 0.010217664763331413, 0.004602581728249788, -0.006902217864990234, 0.0014881460228934884, 0.03036181814968586, -0.007120600901544094, -0.027608871459960938, 0.010594871826469898, -0.024855926632881165, 0.020726507529616356, 0.038832422345876694, 0.04351772367954254, 0.007497807499021292, -0.005274273920804262, 0.008152955211699009, -0.012752228416502476, -0.006888982839882374, 0.01549855712801218, -0.0008114904048852623, -0.05032067745923996, -0.009145604446530342, -0.004662140738219023, 0.0012896162224933505, -0.002771144500002265, -0.013374288566410542, -0.024975044652819633, -0.013255170546472073, -0.02399563044309616, 0.02010444737970829, -0.00011446481948951259, -0.022764746099710464, 0.003474270924925804, -0.022817688062787056, -0.007451483979821205, -0.037058889865875244, 0.018635326996445656, 0.017470618709921837, -0.01057501882314682, 0.010945607908070087, 0.00010014379222411662, -0.013791200704872608, 0.008291926234960556, 0.02292357012629509, -0.02190444990992546, -0.047779496759176254, 0.007001482881605625, -0.03936183452606201, 0.002165628829970956, 0.019244151189923286, -0.007855161093175411, 0.010998548939824104, -0.007894867099821568, 0.0019009225070476532, 0.01891326904296875, -0.019045621156692505, -0.0018595621222630143, 0.01582944020628929, 0.005304053425788879, -0.0033882413990795612, 0.01676914654672146, 0.02367798238992691, 0.0357353575527668, 0.009403693489730358, -0.01592208631336689, 0.008086779154837132, 0.005079052876681089, 0.011613991111516953, -0.011044872924685478, 0.008411044254899025, 0.0019406283972784877, 0.010032370686531067, 0.028111813589930534, -0.019164739176630974, 0.00026863557286560535, 0.017880914732813835, -0.023108864203095436, 0.0048308908008039, 0.01189855020493269, -0.013883847743272781, -0.015789734199643135, -0.011746344156563282, 0.006968394853174686, -0.017073560506105423, 0.00020969705656170845, -0.010416194796562195, 0.026113281026482582, -0.00906619243323803, -0.034703001379966736, -0.018727974966168404, -0.020911801606416702, 0.03761477395892143, 0.007325748447328806, 0.03483535721898079, -0.010495606809854507, 0.009675017558038235, 0.007736043073236942, 0.0021044155582785606, 0.014214730821549892, -0.016954442486166954, 0.006161040160804987, 0.016808852553367615, -0.011216931976377964, 0.013466935604810715, -0.014360319823026657, -0.03480888530611992, 0.015591204166412354, 0.02126915566623211, -0.008563250303268433, 0.029117697849869728, 0.006204055156558752, 0.0050261118449270725, 0.04198242723941803, -0.0077558960765600204, 0.014108848758041859, -0.02771475538611412, -0.002031621290370822, 0.028455933555960655, -0.004324640147387981, -0.01459855493158102, 0.03724418208003044, -0.011607373133301735, 0.025027984753251076, 0.014850025996565819, -0.017616206780076027, -0.014413260854780674, -0.016398558393120766, 0.023744160309433937, -0.007590454537421465, 0.0010621342808008194, 0.004913611803203821, -0.011322814039885998, 0.013374288566410542, -0.0023211438674479723, 0.04060595482587814, 0.020594153553247452, 0.01131619606167078, 0.0063264816999435425, 0.0005141093861311674, -0.0019489005208015442, 0.021136801689863205, -0.014241201803088188, 0.02027650736272335, -0.013658847659826279, -0.01047575380653143, 0.0014302415074780583, -0.011587520129978657, -0.009509575553238392, 0.009886782616376877, -0.04407360777258873, 0.02129562571644783, 0.03298241272568703, 0.016054440289735794, 0.028667697682976723, 0.015789734199643135, 0.04269713535904884, -0.0038779480382800102, -0.04375595971941948, 0.032029468566179276, -0.006088246125727892, -0.007722807582467794, -0.019747093319892883, -0.050479501485824585, 0.01818532682955265, -0.0006812052452005446, -0.022791216149926186, -0.0007928782142698765, 0.01893973909318447, -0.0055489069782197475, 0.011097813956439495, -0.01755003072321415, 0.01330811157822609, 0.030811818316578865, -0.0024022101424634457, -0.006634202785789967, -0.0165044404566288, 0.0082058971747756, 0.00917869247496128, -0.03457064926624298, -0.02066033147275448, 0.03581476956605911, -0.03240005671977997, -0.04412654787302017, 0.009509575553238392, 0.0010513805318623781, 0.0005517472745850682, 0.006323173176497221, 0.004198904614895582, 0.024763278663158417, -0.0015617674216628075, 0.01978679932653904, 0.0036893447395414114, 0.0005116277607157826, 0.018529444932937622, 0.016689734533429146, 0.017192676663398743, 0.002797615248709917, -0.037667714059352875, 0.003290630877017975, 0.01993238739669323, 0.0627354085445404, 0.02391621842980385, -0.019442681223154068, 0.007233100943267345, -0.04203536733984947, -0.018820621073246002, -0.019972093403339386, -0.018238266929984093, -0.0012730720918625593, 0.018608856946229935, -0.02547798678278923, -0.011236784979701042, 0.010819871909916401, 0.017298560589551926, 0.00894707441329956, 0.011799285188317299, 0.01990591734647751, -0.009694869630038738, -0.023783866316080093, -0.008318397216498852, 0.007550748530775309, -0.01876768097281456, 0.011163990013301373, 0.021785331889986992, 0.04412654787302017, -0.014797084964811802, 0.012421345338225365, 0.010872812941670418, -0.016319146379828453, -0.02795299142599106, -0.0013888811226934195, 0.005979054607450962, -0.0034775796812027693, 0.013950024731457233, -0.008550015278160572, 0.030758878216147423, 0.010601489804685116, 0.019588269293308258, -0.0026007399428635836, -0.00861619133502245, 0.032055940479040146, 0.029382405802607536, 0.004099639598280191, -0.005939348600804806, -0.014016201719641685, -0.04028830677270889, 0.0032509248703718185, 0.017205912619829178, -0.004198904614895582, -0.009635311551392078, 0.005694495514035225, -0.0008627772331237793, -0.04404713585972786, -0.0055489069782197475, 0.023876512423157692, 0.002595776692032814, 0.003844859777018428, 2.892640623031184e-05, -0.004867287818342447, -0.013619141653180122, -0.007683102041482925, -0.0421941913664341, -0.007835308089852333, -0.021480919793248177, 0.01203090324997902, 0.015008850023150444, -0.0016808853251859546, 0.02117650769650936, -0.026272105053067207, 0.010839724913239479, -0.009900017641484737, -0.03989124670624733, -0.053417742252349854, -0.0049930233508348465, 0.016663264483213425, 0.0023691218812018633, 0.01937650516629219, -0.004447066690772772, -0.005042655859142542, 0.006988247856497765, -0.003748903749510646, -0.012004433199763298, 0.0035106679424643517, -0.025663280859589577, -0.013063258491456509, -0.01908532716333866, -0.014889732003211975, -0.008199279196560383, -0.019998565316200256, -0.003123534843325615, -0.00011198319407412782, 0.0019141577649861574, -0.01563091017305851, 0.01874120905995369, -0.009800752624869347, 0.03356476500630379, 0.006541555747389793, 0.006501849740743637, 0.010098547674715519, -0.04256477952003479, -0.026126516982913017, -0.026073575019836426, -0.018992681056261063, -0.012540463358163834, 0.005277582909911871, -0.016226498410105705, 0.0313677042722702, 0.017417678609490395, -0.005952584091573954, -0.012408110313117504, 0.020792683586478233, 0.004275007639080286, 0.01621326431632042, 0.010065458714962006, -0.0035966974683105946, -0.012414728291332722, 0.028138285502791405, 0.009827223606407642, 0.02333386428654194, -0.03809124231338501, -0.016027970239520073, -0.04478831589221954, 0.03930889442563057, 0.009125751443207264, -0.018992681056261063, 0.020819153636693954, 0.005224641412496567, 0.0012639728374779224, -0.02396916039288044, 0.024882396683096886, -0.0027264754753559828, 0.03449123725295067, -0.018105914816260338, -0.019508857280015945, -0.03157946839928627, -0.0008007367141544819, -0.027582401409745216, 0.012778699398040771, -0.02603386901319027, -0.006690452806651592, 0.01503532100468874, 0.021282389760017395, -0.00029034976614639163, -0.0018595621222630143, 0.017338266596198082, -0.022738276049494743, -0.013751494698226452, 0.02336033619940281, 0.020726507529616356, 0.035311825573444366, -0.02120297960937023, 0.02710593119263649, -0.028217697516083717, -0.03547064960002899, 0.018225032836198807, 0.005340450443327427, 0.0071470714174211025, 0.009019868448376656, 0.02742357738316059, 0.014360319823026657, 0.02824416756629944, -0.0061676581390202045, 0.011031636968255043, 0.018317678943276405, -0.017589736729860306, -0.005588612984865904, 0.002041547792032361, -0.0004963243845850229, -0.014055906794965267, -0.008311779238283634, 0.022963276132941246, 0.005591921508312225, 0.009350751526653767, -0.015247086063027382, 0.005105523858219385, 0.010376488789916039, 0.007425012998282909, -0.007107365410774946, -0.023280924186110497, -0.003947433549910784, -0.012871346436440945, 0.012778699398040771, -0.015736792236566544, 0.019217681139707565, -0.010647812858223915, -0.010753695853054523, 0.01007869467139244, -0.006458834744989872, 0.021110331639647484, 0.006309937685728073, 0.010098547674715519, -0.010177958756685257, -0.009125751443207264, 0.020845625549554825, 0.026682401075959206, -0.028455933555960655, 0.005406627431511879, -0.055588334798812866, -0.004093022085726261, 0.020461801439523697, -0.007332365959882736, 0.008397809229791164, 0.021639743819832802, -0.01655738241970539, 0.02132209576666355, -0.01835738494992256, 0.00658787926658988, 0.005806995555758476, -0.024220630526542664, -0.032029468566179276, -0.005787142552435398, -0.041214779019355774, -0.020475035533308983, -0.02071327157318592, 0.007947808131575584, 0.007001482881605625, 0.026100046932697296, 0.019575035199522972, -0.03814418613910675, -0.025226514786481857, 0.034650061279535294, 0.005019494332373142, 0.042432427406311035, -0.013480170629918575, 0.012619875371456146, -0.0025841956958174706, -0.00200515054166317, -0.010654430836439133, 0.01177943218499422, 0.009271339513361454, -0.0012722448445856571, 0.009555899538099766, -0.004748170264065266, 0.02088533155620098, -0.01774856075644493, 0.03838242217898369, -0.007094130385667086, 0.00047274900134652853, -0.03692653775215149, 0.03576182946562767, -0.005148538388311863, 0.007352218963205814, -0.01317575853317976, -0.02885299175977707, -0.012877964414656162, 0.000289936171611771, -0.008503691293299198, 0.013751494698226452, -0.0032095646020025015, -0.012626493349671364, 0.0027182032354176044, 0.016027970239520073, 0.024975044652819633, -0.00039685273077338934, -0.022473569959402084, -0.003313792636618018, 0.024154454469680786, -0.01531326211988926, -0.022685334086418152, -0.0003348121827002615, 0.008424279280006886, 0.03131476044654846, 0.002969674300402403, 0.014823555946350098, 0.019125033169984818, 0.006740085314959288, 0.02051474153995514, 5.816301609229413e-07, 0.0037753742653876543, 0.03253240883350372, -0.04815008491277695, -0.007080894894897938, 0.0038051537703722715, -0.008536780253052711, -0.006773173809051514, -0.020117683336138725, -0.007094130385667086, 0.007921337150037289, -0.015816204249858856, 0.005214714910835028, 0.019945623353123665, -0.007365453988313675, -0.02647063508629799, 0.014426495879888535, -0.0021391580812633038, -0.03224123269319534, 0.00217224657535553, -0.0033171013928949833, 0.01519414409995079, -0.027317695319652557, -0.008622809313237667, 0.00659449677914381, 0.01612061634659767, 0.018172090873122215, -0.009999282658100128, -0.021600037813186646, -0.007332365959882736, 0.023082394152879715, -0.02071327157318592, 0.0025610339362174273, -0.00129457947332412, 0.009350751526653767, 0.0034411826636642218, 0.012368404306471348, -0.00017443734395783395, 0.0012449470814317465, 0.012169874273240566, -0.02574269287288189, -0.01725885458290577, 0.009489722549915314, -0.008735309354960918, 0.0006497713620774448, -0.0005186590133234859, 0.0007610307657159865, 0.00788824912160635, -0.009456634521484375, -0.004367654677480459, 8.101462299237028e-05, 0.009708105586469173, 0.020752977579832077, -0.013605906628072262, -0.0013773002428933978, 0.008695603348314762, -0.019045621156692505, -0.008371338248252869, -0.01670297048985958, -0.01400296576321125, -0.019852975383400917, -0.03875301033258438, 0.001137410057708621, 0.0010166377760469913, 0.011283108033239841, -0.0004541368398349732, 0.0073389834724366665, -0.02280445210635662, 0.008536780253052711, -0.012686051428318024, 0.015247086063027382, -0.018238266929984093, 0.008225750178098679, 0.006700379308313131, 0.023664748296141624, 0.04267066344618797, 0.006829423829913139, -0.037032417953014374, -0.012911052443087101, -0.0002858001389540732, -0.012189727276563644, -0.034120649099349976, -0.019270623102784157, -0.02885299175977707, 0.040076542645692825, 0.0027347474824637175, -0.007027953397482634, 0.0022864011116325855, -0.009105898439884186, -0.05217362195253372, -0.013738259673118591, -0.007378689479082823, 0.014519142918288708, 0.00399375706911087, 0.036158885806798935, 0.0014467856381088495, 0.02385004237294197, 0.00269835046492517, 0.020527977496385574, -0.011362520046532154, -0.004056624602526426, -0.015591204166412354, -0.0014029436279088259, -0.009681634604930878, 4.9865091568790376e-05, -0.022672098129987717, 0.005201479885727167, 0.01978679932653904, -0.03353829309344292, -0.008854427374899387, 0.034094177186489105, -0.02707945927977562, -0.030202994123101234, 0.01446620188653469, 0.026391223073005676, 0.0063364082016050816, 0.012970611453056335, 0.023002982139587402, -0.006170966662466526, -0.011746344156563282, -0.008013985119760036, -0.01072060689330101, -0.006902217864990234, -0.005922804586589336, 0.005979054607450962, 0.022182391956448555, 0.0041261101141572, 0.004533096216619015, -0.005896334070712328, 0.01056178379803896, -0.011177225969731808, 0.04349125176668167, -0.0011961418204009533, -0.00729265995323658, 0.022327980026602745, 0.0049533178098499775, -0.0041261101141572, -0.007259571459144354, -0.012877964414656162, -0.006213981658220291, 0.0003195088356733322, 0.026947107166051865, -0.02710593119263649, -0.03507359325885773, -0.00813310220837593, 0.00802060216665268, -0.022301509976387024, -0.010290459729731083, -0.006329790689051151, 0.00044586474541574717, -0.032373588532209396, 0.029355933889746666, -0.007008100859820843, -0.023426512256264687, 0.013804435729980469, -0.005045964848250151, 0.0199588593095541, -0.016517676413059235, -0.017364736646413803, 0.01256693433970213, 0.0042154486291110516, 0.031129466369748116, 0.014400025829672813, -0.010436047799885273, -0.02394269034266472, 0.0052411858923733234, 0.01900591515004635, -0.006723541300743818, -0.009119133464992046, 0.18497680127620697, -0.03330006077885628, 0.0033981676679104567, 0.00587648106738925, -0.007120600901544094, 0.004417287185788155, 0.029567699879407883, 0.016292676329612732, -0.007947808131575584, -0.01226252131164074, 0.004781258292496204, 0.009324281476438046, -0.029938288033008575, 0.012335316278040409, 0.025319162756204605, -0.03570888563990593, -0.039203010499477386, -0.043332431465387344, 0.0015625946689397097, 0.003732359502464533, -0.03150005638599396, 0.012209580279886723, 0.001576657174155116, -0.025676516816020012, 0.009721340611577034, 0.0017983487341552973, 0.0018347458681091666, -0.004903685301542282, 0.019892681390047073, 0.022102979943156242, -0.01271252240985632, 0.00551912747323513, 0.007908102124929428, 0.018264738842844963, -0.0010522077791392803, -0.000166578873177059, 0.0025130559224635363, 0.006538246758282185, 0.001412870129570365, 0.013910318724811077, 0.014413260854780674, 0.005456259474158287, 0.012540463358163834, -0.02690740115940571, 0.019535329192876816, 0.032903000712394714, -0.023902984336018562, -0.01400296576321125, 0.01021104771643877, 0.006379423197358847, -0.01108457800000906, 0.022857394069433212, 0.0006220599170774221, 0.040923602879047394, 0.005333832930773497, 0.02396916039288044, -0.025094162672758102, 0.0029465125408023596, 0.014333848841488361, 0.00364632997661829, -0.0378265380859375, 0.0013466936070472002, 0.005469494964927435, 0.02983240596950054, 0.01387061271816492, 0.01293090544641018, 2.5010097033373313e-06, 0.00012945795606356114, 0.004198904614895582, -0.009966193698346615, -0.015670616179704666, -0.012606640346348286, -0.015339733101427555, -0.002794306492432952, -0.035311825573444366, -0.028667697682976723, 0.020819153636693954, 0.0336441770195961, 0.01117060799151659, 0.03716477006673813, -0.014082377776503563, -0.02414121851325035, 0.006283467169851065, -0.011124284006655216, 0.0025875046849250793, -0.009622075594961643, 0.008391191251575947, -0.02684122323989868, -0.01490296795964241, -0.02562357485294342, 0.0017569883493706584, -0.0008966927416622639, -0.0020299667958170176, 0.005823539569973946, 0.00539670092985034, 0.001287961844354868, 0.020236801356077194, -0.010965460911393166, 0.0002554002567194402, -0.020408859476447105, -0.04399419575929642, 0.034120649099349976, 0.04320007562637329, 0.02085885964334011, -0.004748170264065266, -0.0011837336933240294, 0.01549855712801218, 0.012560316361486912, -0.017007382586598396, -0.015855910256505013, -0.0010083657689392567, -0.05781186744570732, 0.016305910423398018, -0.012547081336379051, -0.017060324549674988, 0.008126485161483288, -0.0048970673233270645, -0.002397246891632676, 0.008258838206529617, 0.0022251878399401903, -0.014280907809734344, -0.017325030639767647, 0.0030871378257870674, -0.010376488789916039, -0.006395967211574316, -0.03867359831929207, -0.024511808529496193, -0.004900376312434673, -0.025729456916451454, 0.007054424379020929, 0.0058599370531737804, -0.040394190698862076, 0.018119148910045624, 0.006303320173174143, 0.002800924004986882, -0.014307377859950066, -0.004423904698342085, 0.009258104488253593, -0.0019522093934938312, 0.008708839304745197, -0.007352218963205814, 0.0057077305391430855, -0.018555914983153343, -0.013486788608133793, 0.025636810809373856, -0.005469494964927435, -0.007583837024867535, 0.026166222989559174, 0.008695603348314762, -0.01385737769305706, -0.00938384048640728, 0.0029266595374792814, 0.012831640429794788, -0.02297651208937168, 0.015352968126535416, 0.005833466071635485, -0.02827063761651516, 0.0012441198341548443, 0.021401507779955864, -0.008986780419945717, -0.039123598486185074, -0.025835338979959488, 0.012057374231517315, -0.00492353830486536, 0.008543397299945354, -0.002021694788709283, -0.16432970762252808, -0.010912518948316574, 0.011144137009978294, -0.03375006094574928, 0.018410326912999153, 0.03189711645245552, -0.0015783116687089205, -0.012196345254778862, -0.024922102689743042, -0.0006170966662466526, 0.004222066141664982, -0.021401507779955864, -0.013288258574903011, -0.008139720186591148, -0.026867695152759552, 0.001307814847677946, 0.01845003291964531, -0.003851477289572358, 0.017470618709921837, 0.010555165819823742, 0.05029420554637909, -0.035311825573444366, -0.015961792320013046, 0.005919495597481728, -0.0003114435530733317, -0.003297248389571905, -0.0041426545940339565, 0.02437945455312729, 0.004513243213295937, -0.04187654331326485, -0.00574412802234292, -0.019998565316200256, 0.03157946839928627, -0.008371338248252869, 0.005936040077358484, 0.026920635253190994, 0.0300971120595932, -0.005072435364127159, -0.027092695236206055, 0.00108943204395473, 0.023770630359649658, 0.023347100242972374, 0.0018595621222630143, 0.0038978010416030884, -0.019283857196569443, 0.005856628064066172, 0.03774712607264519, -0.0342794731259346, -0.006210672669112682, -0.004450375679880381, 0.018754445016384125, -0.01745738461613655, 0.0022996363695710897, -0.0024170998949557543, -0.0009000016143545508, 0.002223533345386386, -0.007312512956559658, 0.0048341997899115086, -0.0206868015229702, -0.02054121345281601, -0.0018727973802015185, -0.015882380306720734, -0.00021776233916170895, -0.0011771160643547773, 0.008563250303268433, -0.022592686116695404, -0.019151505082845688, 0.02326768822968006, -0.029302993789315224, -0.0020845625549554825, -0.021520625799894333, 0.0032476161140948534, -0.0010397996520623565, -0.005244494415819645, 0.022248568013310432, 0.01900591515004635, -0.008146338164806366, 0.004533096216619015, 0.025544162839651108, -0.005009567830711603, -0.018979445099830627, 0.020091211423277855, -0.00847060326486826, -0.006525011733174324, -0.009615458548069, -0.02696034125983715, -0.009112516418099403, 0.01676914654672146, -0.033803001046180725, -0.0020944890566170216, 0.029594169929623604, -0.019416211172938347, -0.00880148634314537, -0.011726491153240204, -0.006243761163204908, 0.0026586444582790136, 0.015379439108073711, -0.01784120872616768, -0.0042783161625266075, 0.0011994506930932403, -0.004645596258342266, 0.01318899355828762, 0.00043180224020034075, -0.007233100943267345, 0.020183859393000603, 0.004950008820742369, -0.012851493433117867, 0.007775749079883099, 0.027635343372821808, -0.015842674300074577, -0.00706765940412879, -0.021838273853063583, -0.004447066690772772, 0.013182376511394978, -0.008841192349791527, 0.004288242664188147, -0.004906993824988604, -0.01731179468333721, 0.029726523905992508, 0.016173558309674263, 0.05397362634539604, -0.007107365410774946, -0.0029432037845253944, 0.015247086063027382, -0.004668758250772953, -0.01711326465010643, -0.12504728138446808, -0.0312353502959013, -0.008675750344991684, 0.020925037562847137, -0.015869146212935448, 0.02557063288986683, -0.0055356714874506, 0.04267066344618797, -0.025372102856636047, 0.03981183469295502, -0.04018242284655571, 0.003245961619541049, 0.014651496894657612, -0.013711788691580296, 0.0172323826700449, -0.0051551563665270805, 0.01575002819299698, -0.004860670305788517, -0.02737063728272915, 0.03038828819990158, -0.022473569959402084, -0.004629052244126797, -0.005641554016619921, -0.017629442736506462, -0.0009736230713315308, 0.00989339966326952, -0.024127984419465065, 0.022407392039895058, 0.0129573754966259, -0.009330898523330688, 0.021533861756324768, -0.036158885806798935, -0.0025444896891713142, -0.022235333919525146, 0.026219164952635765, 1.7474754713475704e-05, -0.0061676581390202045, -0.014545613899827003, 0.022738276049494743, -0.010826489888131618, 2.6082881959155202e-05, -0.005376847926527262, 0.0021540478337556124, -0.014810319989919662, 0.00036355762858875096, -0.021891215816140175, -0.02521328069269657, 0.0220500398427248, -0.006127952132374048, -0.021533861756324768, -0.017536796629428864, -0.03036181814968586, -0.05977069213986397, 0.024644160643219948, 0.041797131299972534, 0.007226483430713415, 0.007014718372374773, 0.006233834661543369, -0.009754428640007973, 0.0039904480800032616, -0.01199781522154808, -0.005558833479881287, -0.03668830171227455, 0.015379439108073711, 0.01580296829342842, 0.0029398947954177856, -0.00884780939668417, -0.02795299142599106, 0.005416553933173418, -0.026166222989559174, -0.0012482558377087116, 0.01387061271816492, -0.00997942965477705, 0.00576067203655839, -0.009198545478284359, 0.016133852303028107, -0.015207380056381226, -0.01827797293663025, -0.004093022085726261, 0.0002167283237213269, -0.014214730821549892, -0.008417662233114243, 0.0010844687931239605, -0.018092678859829903, -0.01048898883163929, 0.002655335469171405, -0.002028312301263213, -0.023664748296141624, 0.0012540463358163834, -0.03375006094574928, 0.01969415321946144, 0.026655929163098335, 0.029885346069931984, -0.014069142751395702, 0.003027578815817833, -0.004701846744865179, -0.02513386867940426, -0.004308095667511225, 0.012864728458225727, 0.02408827841281891, -0.012626493349671364, 0.0026685709599405527, -0.04889126121997833, 0.029858876019716263, 0.008682368323206902, -0.00658126175403595, 0.0020200402941554785, -0.03221476450562477, 0.008113249205052853, -0.006498540751636028, 0.008404426276683807, 0.02161327376961708, -0.020594153553247452, 0.007127218414098024, 0.000653907423838973, -0.0017586428439244628, -0.03626476973295212, -0.009833840653300285, 0.015061791054904461, -0.017444148659706116, 0.019138269126415253, 0.01940297521650791, 0.008880898356437683, -0.004840817302465439, 0.006558099761605263, 0.020527977496385574, 0.01387061271816492, -0.023505924269557, -0.012110315263271332, 0.027767695486545563, -0.003844859777018428, -0.008973545394837856, -0.00551912747323513, -0.022500040009617805, 0.00040512479608878493, 0.002003496279940009, -0.013281641528010368, -0.01874120905995369, 0.007246336434036493, 0.005214714910835028, -0.0007246336317621171, 0.03547064960002899, -0.025676516816020012, -0.055588334798812866, 0.005105523858219385, 0.001349175232462585, 0.0009703141986392438, -0.0066474382765591145, 0.0007130527519620955, -0.0221426859498024, 0.020620625466108322, 0.0018529444932937622, 0.03533829748630524, 0.01743091270327568, -0.02394269034266472, -0.03541770949959755, -0.019217681139707565, 0.032002996653318405, 0.03835595026612282, 0.013228699564933777, 0.0004479327762965113, 0.03126182034611702, 0.03353829309344292, 0.005902951583266258, 0.015379439108073711, -0.004053316079080105, -0.011733109131455421, -0.019098563119769096, -0.01062134187668562, 0.0006654883036389947, 0.0027413652278482914, -0.012652963399887085, 0.007808837573975325, 0.01835738494992256, 0.012977228499948978, 0.01702061854302883, 0.01531326211988926, -0.0013102964730933309, 0.002633828204125166, -0.015525027178227901, -0.02199709787964821, 0.01784120872616768, 0.005955893080681562, 0.00610809912905097, 0.01920444518327713, 0.023611806333065033, 0.01609414629638195, 0.00446691969409585, -0.02600739896297455, 0.008278691209852695, -0.008563250303268433, -0.00030999595765024424, 0.008397809229791164, 0.006127952132374048, 0.006515085231512785, 0.018344150856137276, 0.0012341933324933052, -0.0013301493600010872, 0.011283108033239841, -0.007782366592437029, 0.029382405802607536, 0.0015725211706012487, 0.019548563286662102, -0.023863278329372406, 0.0006121334154158831, -0.025663280859589577, -0.026947107166051865, -0.0032095646020025015, -0.018463268876075745, 0.0013979803770780563, 0.022566216066479683, 0.03065299615263939, 0.008682368323206902, -0.018542679026722908, 0.014625025913119316, 0.006273540668189526, -0.007001482881605625, 0.02475004456937313, -0.0014467856381088495, -0.024670632556080818, -0.03314123675227165, 0.008900751359760761, 0.030600054189562798, -0.0025080926716327667, 0.05632951110601425, 0.0054529509507119656, 0.015352968126535416, 0.03483535721898079, 0.012381639331579208, -0.03277064487338066, 0.037323594093322754, 0.010065458714962006, -0.027264753356575966, -0.023082394152879715, -0.015220615081489086, -0.009019868448376656, -0.03822359815239906, 0.000467785750515759, 0.0020779448095709085, -0.000248369004111737, 0.015855910256505013, 0.08740603923797607, 0.02248680405318737, -0.012507375329732895, 0.019972093403339386, -0.017007382586598396, 0.01398973073810339, 0.009357369504868984, 0.013844141736626625, -0.006941923871636391, 0.0018628709949553013, 0.00858310330659151, 0.009800752624869347, -0.009701487608253956, -0.02666916511952877, -0.01969415321946144, -0.020289741456508636, -0.006018760614097118, 0.02832357957959175, -0.019244151189923286, -0.011223549023270607, 0.01699414849281311, -0.010482371784746647, 0.02044856548309326, 0.0034080941695719957, -0.004410669673234224, -0.0013045059749856591, 0.03533829748630524, 0.0011680168099701405, 0.010766930878162384, -0.010846342891454697, 0.04521184414625168, 0.02355886436998844, -0.021057389676570892, -0.012639728374779224, 0.0068492768332362175, 0.010131635703146458, 0.009787517599761486, -0.03152652457356453, -0.0011514726793393493, 0.0033882413990795612, 0.008172808215022087, 0.020898565649986267, 0.009900017641484737, -0.03613241761922836, -0.0013739913702011108, -0.001259836833924055, 0.0012292300816625357, -0.0242338664829731, -0.02117650769650936], index=0, object='embedding')], model='text-embedding-ada-002', object='list', usage=Usage(prompt_tokens=1696, total_tokens=1696))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "oai_client = OpenAI()\n",
        "\n",
        "oai_client.embeddings.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=llm_details\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4icTyiBoojuJ"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
        "\n",
        "embedding_function = OpenAIEmbeddingFunction(api_key=os.environ.get('OPENAI_API_KEY'),\n",
        "                                             model_name=\"text-embedding-ada-002\")\n",
        "\n",
        "\n",
        "chroma_client = chromadb.Client()\n",
        "vector_store = chroma_client.get_or_create_collection(name=\"llm_details\",\n",
        "                                                      embedding_function=embedding_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "-xRsC40-ojuK"
      },
      "source": [
        "Add the university_info to the embedding database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_YIV5S0ojuL"
      },
      "outputs": [],
      "source": [
        "vector_store.add(\"llm_details\", documents=llm_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq1e59X0ojuL"
      },
      "source": [
        "## Build RAG from scratch\n",
        "\n",
        "Build a custom RAG from scratch, and add TruLens custom instrumentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8XKWZ9MojuL"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import Tru\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "tru = Tru()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dta7aMLhojuM"
      },
      "outputs": [],
      "source": [
        "class RAG_from_scratch:\n",
        "    @instrument\n",
        "    def retrieve(self, query: str) -> list:\n",
        "        \"\"\"\n",
        "        Retrieve relevant text from vector store.\n",
        "        \"\"\"\n",
        "        results = vector_store.query(\n",
        "        query_texts=query,\n",
        "        n_results=2\n",
        "    )\n",
        "        return results['documents'][0]\n",
        "\n",
        "    @instrument\n",
        "    def generate_completion(self, query: str, context_str: list) -> str:\n",
        "        \"\"\"\n",
        "        Generate answer from context.\n",
        "        \"\"\"\n",
        "        completion = oai_client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=0,\n",
        "        messages=\n",
        "        [\n",
        "            {\"role\": \"user\",\n",
        "            \"content\":\n",
        "            f\"We have provided context information below. \\n\"\n",
        "            f\"---------------------\\n\"\n",
        "            f\"{context_str}\"\n",
        "            f\"\\n---------------------\\n\"\n",
        "            f\"Given this information, please answer the question: {query}\"\n",
        "            }\n",
        "        ]\n",
        "        ).choices[0].message.content\n",
        "        return completion\n",
        "\n",
        "    @instrument\n",
        "    def query(self, query: str) -> str:\n",
        "        context_str = self.retrieve(query)\n",
        "        completion = self.generate_completion(query, context_str)\n",
        "        return completion\n",
        "\n",
        "rag = RAG_from_scratch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCbo9mQIojuM"
      },
      "source": [
        "## Set up feedback functions.\n",
        "\n",
        "Here we'll use groundedness, answer relevance and context relevance to detect hallucination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE3aGi8dojuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c9e234-b621-4055-cfdb-98f9d3922959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
            "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "✅ In Answer Relevance, input prompt will be set to __record__.app.retrieve.args.query .\n",
            "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "✅ In Context Relevance, input question will be set to __record__.app.retrieve.args.query .\n",
            "✅ In Context Relevance, input statement will be set to __record__.app.retrieve.rets.collect() .\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval import Feedback, Select\n",
        "from trulens_eval.feedback import Groundedness\n",
        "from trulens_eval.feedback.provider.openai import OpenAI as fOpenAI\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Initialize provider class\n",
        "fopenai = fOpenAI()\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=fopenai)\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .on_output()\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = (\n",
        "    Feedback(fopenai.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
        "    .on(Select.RecordCalls.retrieve.args.query)\n",
        "    .on_output()\n",
        ")\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(fopenai.qs_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
        "    .on(Select.RecordCalls.retrieve.args.query)\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxRl-LGPojuN"
      },
      "source": [
        "## Construct the app\n",
        "Wrap the custom RAG with TruCustomApp, add list of feedbacks for eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rLJGbKBojuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946ff888-0d2d-4aa6-91bc-253f66186aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trulens_eval.tru_custom_app:Function <function RAG_from_scratch.retrieve at 0x7b9e68cbf400> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.RAG_from_scratch object at 0x7b9e63fc52a0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
            "WARNING:trulens_eval.tru_custom_app:Function <function RAG_from_scratch.generate_completion at 0x7b9e68cbfa30> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.RAG_from_scratch object at 0x7b9e63fc52a0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
            "WARNING:trulens_eval.tru_custom_app:Function <function RAG_from_scratch.retrieve at 0x7b9e62ee6830> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.RAG_from_scratch object at 0x7b9e63fc52a0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
            "WARNING:trulens_eval.tru_custom_app:Function <function RAG_from_scratch.query at 0x7b9e68cbfac0> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.RAG_from_scratch object at 0x7b9e63fc52a0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
            "WARNING:trulens_eval.tru_custom_app:Function <function RAG_from_scratch.generate_completion at 0x7b9e62ee68c0> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.RAG_from_scratch object at 0x7b9e63fc52a0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
            "WARNING:trulens_eval.tru_custom_app:Function <function RAG_from_scratch.query at 0x7b9e62ee6950> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.RAG_from_scratch object at 0x7b9e63fc52a0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
            "WARNING:trulens_eval.tru_custom_app:Function <function RAG_from_scratch.generate_completion at 0x7b9e68cbf370> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.RAG_from_scratch object at 0x7b9e63fc52a0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
            "WARNING:trulens_eval.tru_custom_app:Function <function RAG_from_scratch.retrieve at 0x7b9e68cbf9a0> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.RAG_from_scratch object at 0x7b9e63fc52a0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
            "WARNING:trulens_eval.tru_custom_app:Function <function RAG_from_scratch.query at 0x7b9e68cbf5b0> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.RAG_from_scratch object at 0x7b9e63fc52a0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "tru_rag = TruCustomApp(rag,\n",
        "    app_id = 'RAG-Ask_about_LLM',\n",
        "    feedbacks = [f_groundedness, f_qa_relevance, f_context_relevance])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dmuPHwHojuN"
      },
      "source": [
        "## Run the app\n",
        "Use `tru_rag` as a context manager for the custom RAG-from-scratch app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqlLaiEoojuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbbd7d01-a7b7-4593-d4d6-f20e07023a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 2 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        }
      ],
      "source": [
        "with tru_rag as recording:\n",
        "    rag.query(\"Does LLM help to write codes ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hltu6QwvojuO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "cbb4cd9b-42f7-4c7c-83c8-f877c2696187"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Groundedness  Context Relevance  Answer Relevance  latency  \\\n",
              "app_id                                                                          \n",
              "RAG-Ask_about_LLM      0.766667                1.0               1.0      2.0   \n",
              "\n",
              "                   total_cost  \n",
              "app_id                         \n",
              "RAG-Ask_about_LLM     0.00284  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63273213-e15a-40e5-936b-f24b44608bff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Groundedness</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RAG-Ask_about_LLM</th>\n",
              "      <td>0.766667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.00284</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63273213-e15a-40e5-936b-f24b44608bff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63273213-e15a-40e5-936b-f24b44608bff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63273213-e15a-40e5-936b-f24b44608bff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tru\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Groundedness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7666666666666666,\n        \"max\": 0.7666666666666666,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Context Relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer Relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.00284,\n        \"max\": 0.00284,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.00284\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "tru.get_leaderboard(app_ids=[\"RAG-Ask_about_LLM\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-dEIwdaojuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f10705-c3aa-4091-f9f5-94c6dc7b68f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dashboard ...\n",
            "npx: installed 22 in 3.86s\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://common-dancers-roll.loca.lt\n",
            "\n",
            "  Submit this IP Address: 34.106.72.115\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tru.run_dashboard()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "trulens18_release",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}